{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73d1b6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0n/ctg0g4y91vz7y7mppc3gtnph0000gn/T/ipykernel_61229/1603200369.py:161: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right')\n",
      "/var/folders/0n/ctg0g4y91vz7y7mppc3gtnph0000gn/T/ipykernel_61229/1603200369.py:231: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  ax = sns.barplot(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All visualizations have been generated and saved to the 'visualizations' folder!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.ticker as mtick\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Set the style for the plots\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "\n",
    "# Define a custom color palette for the models\n",
    "palette = {\"Google\": \"#4285F4\", \"ChatGPT\": \"#19C37D\", \"Claude\": \"#8C43EA\"}\n",
    "\n",
    "# Function to clean numeric values\n",
    "# Function to clean numeric values - FIXED to handle trailing commas and other issues\n",
    "def clean_numeric_value(value):\n",
    "    if value is None or pd.isna(value):\n",
    "        return 0\n",
    "        \n",
    "    if isinstance(value, (int, float)):\n",
    "        return float(value)\n",
    "        \n",
    "    if isinstance(value, str):\n",
    "        # Remove newlines, commas, and any whitespace\n",
    "        cleaned = value.replace('\\n', '').replace(',', '.').strip()\n",
    "        # Handle multiple decimal points by keeping only the first one\n",
    "        if cleaned.count('.') > 1:\n",
    "            parts = cleaned.split('.', 1)\n",
    "            cleaned = parts[0] + '.' + parts[1].replace('.', '')\n",
    "        # Make sure we have a valid number\n",
    "        try:\n",
    "            return float(cleaned)\n",
    "        except ValueError:\n",
    "            # If conversion fails, try to extract the first number found\n",
    "            match = re.search(r'(\\d+\\.?\\d*)', cleaned)\n",
    "            if match:\n",
    "                return float(match.group(1))\n",
    "            return 0\n",
    "    \n",
    "    return 0\n",
    "\n",
    "# Read and process Google data\n",
    "def process_google_data(file_path):\n",
    "    google_df = pd.read_csv(file_path)\n",
    "    processed_data = []\n",
    "    \n",
    "    for _, row in google_df.iterrows():\n",
    "        processed_data.append({\n",
    "            'model': 'Google',\n",
    "            'language': row['Language'],\n",
    "            'examples': 30,  # Fixed at 30 examples based on filename\n",
    "            'bleu_score': clean_numeric_value(row['Bleu Score']),\n",
    "            'syntax_valid_rate': clean_numeric_value(row['Syntax Valid Rate']),\n",
    "            'structure_score': clean_numeric_value(row['Structure Score']),\n",
    "            'semantic_score': clean_numeric_value(row['Semantic Scire ']),  # Note the space\n",
    "            'token_match': clean_numeric_value(row['Token Match']),\n",
    "            'overall': clean_numeric_value(row['Overall'])\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(processed_data)\n",
    "\n",
    "# Read and process ChatGPT/Claude data\n",
    "def process_model_data(file_path, model_name):\n",
    "    # Read the CSV file without header first to inspect the structure\n",
    "    raw_data = pd.read_csv(file_path, header=None)\n",
    "    \n",
    "    # Find the header row (which has 'Language' and 'No of Examples')\n",
    "    header_idx = None\n",
    "    for i, row in raw_data.iterrows():\n",
    "        if 'Language' in row.values and 'No of Examples' in row.values:\n",
    "            header_idx = i\n",
    "            break\n",
    "    \n",
    "    if header_idx is None:\n",
    "        raise ValueError(f\"Could not find header row in {model_name} data\")\n",
    "    \n",
    "    # Extract headers and use them to read the data properly\n",
    "    headers = raw_data.iloc[header_idx].tolist()\n",
    "    data = raw_data.iloc[header_idx+1:].reset_index(drop=True)\n",
    "    data.columns = headers\n",
    "    \n",
    "    # Process the data\n",
    "    processed_data = []\n",
    "    current_language = None\n",
    "    \n",
    "    for _, row in data.iterrows():\n",
    "        if not pd.isna(row['Language']) and row['Language']:\n",
    "            current_language = row['Language']\n",
    "        \n",
    "        if not pd.isna(row['No of Examples']):\n",
    "            processed_data.append({\n",
    "                'model': model_name,\n",
    "                'language': current_language,\n",
    "                'examples': clean_numeric_value(row['No of Examples']),\n",
    "                'bleu_score': clean_numeric_value(row['Bleu Score']),\n",
    "                'syntax_valid_rate': clean_numeric_value(row['Syntax Valid Rate']),\n",
    "                'structure_score': clean_numeric_value(row['Structure Score']),\n",
    "                'semantic_score': clean_numeric_value(row['Semantic Scire ']),  # Note the space\n",
    "                'token_match': clean_numeric_value(row['Token Match']),\n",
    "                'overall': clean_numeric_value(row['Overall'])\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(processed_data)\n",
    "\n",
    "# Main function to generate visualizations\n",
    "def generate_visualizations():\n",
    "    # Read and process all data\n",
    "    google_df = process_google_data('./Results/Google-Google translator using 30 code snippets.csv')\n",
    "    chatgpt_df = process_model_data('./Results/chatGPT-Table 1.csv', 'ChatGPT')\n",
    "    claude_df = process_model_data('./Results/Claude-Table 1.csv', 'Claude')\n",
    "    \n",
    "    # Combine all data\n",
    "    df = pd.concat([google_df, chatgpt_df, claude_df], ignore_index=True)\n",
    "    \n",
    "    # Clean language names for better display\n",
    "    df['language_display'] = df['language'].str.replace(r'\\(.*\\)', '', regex=True).str.strip()\n",
    "    \n",
    "    # Create a directory for saving the visualizations\n",
    "    os.makedirs('visualizations', exist_ok=True)\n",
    "    \n",
    "    # 1. Model comparison chart - compare models across languages\n",
    "    # For fair comparison, use examples=0 for ChatGPT and Claude\n",
    "    comparison_df = pd.DataFrame()\n",
    "    \n",
    "    # Add Google data (always 30 examples)\n",
    "    comparison_df = pd.concat([comparison_df, google_df], ignore_index=True)\n",
    "    \n",
    "    # Add ChatGPT data with 0 examples\n",
    "    for lang in chatgpt_df['language'].unique():\n",
    "        lang_data = chatgpt_df[chatgpt_df['language'] == lang]\n",
    "        zero_examples = lang_data[lang_data['examples'] == 0]\n",
    "        if not zero_examples.empty:\n",
    "            comparison_df = pd.concat([comparison_df, zero_examples.iloc[[0]]], ignore_index=True)\n",
    "    \n",
    "    # Add Claude data with 0 examples\n",
    "    for lang in claude_df['language'].unique():\n",
    "        lang_data = claude_df[claude_df['language'] == lang]\n",
    "        zero_examples = lang_data[lang_data['examples'] == 0]\n",
    "        if not zero_examples.empty:\n",
    "            comparison_df = pd.concat([comparison_df, zero_examples.iloc[[0]]], ignore_index=True)\n",
    "    \n",
    "    # Add language_display column\n",
    "    comparison_df['language_display'] = comparison_df['language'].str.replace(r'\\(.*\\)', '', regex=True).str.strip()\n",
    "    \n",
    "    plt.figure(figsize=(14, 8))\n",
    "    ax = sns.barplot(\n",
    "        x='language_display',\n",
    "        y='overall',\n",
    "        hue='model',\n",
    "        data=comparison_df,\n",
    "        palette=palette\n",
    "    )\n",
    "    \n",
    "    # Customize the plot\n",
    "    ax.set_title('AI Model Translation Performance by Language', fontsize=16)\n",
    "    ax.set_xlabel('Language', fontsize=14)\n",
    "    ax.set_ylabel('Overall Performance Score', fontsize=14)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right')\n",
    "    ax.yaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('visualizations/model_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 2. Create a heatmap for better visualization of performance differences\n",
    "    pivot_df = comparison_df.pivot_table(\n",
    "        index='language_display',\n",
    "        columns='model',\n",
    "        values='overall'\n",
    "    )\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    ax = sns.heatmap(\n",
    "        pivot_df,\n",
    "        annot=True,\n",
    "        fmt='.2f',\n",
    "        cmap='YlGnBu',\n",
    "        vmin=0,\n",
    "        vmax=1,\n",
    "        linewidths=.5\n",
    "    )\n",
    "    \n",
    "    ax.set_title('AI Model Translation Performance Heatmap', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('visualizations/performance_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 3. Create line plots showing performance by example count for each language\n",
    "    languages = df['language'].unique()\n",
    "    \n",
    "    for lang in languages:\n",
    "        # Filter data for this language\n",
    "        lang_df = df[df['language'] == lang]\n",
    "        \n",
    "        # Skip if we don't have multiple example counts\n",
    "        if len(lang_df['examples'].unique()) <= 1:\n",
    "            continue\n",
    "            \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        ax = sns.lineplot(\n",
    "            x='examples',\n",
    "            y='overall',\n",
    "            hue='model',\n",
    "            style='model',\n",
    "            markers=True,\n",
    "            dashes=False,\n",
    "            data=lang_df,\n",
    "            palette=palette\n",
    "        )\n",
    "        \n",
    "        # Format the plot\n",
    "        display_lang = lang.replace('(', '').replace(')', '').strip()\n",
    "        ax.set_title(f'Performance by Example Count: {display_lang}', fontsize=16)\n",
    "        ax.set_xlabel('Number of Examples', fontsize=14)\n",
    "        ax.set_ylabel('Overall Performance Score', fontsize=14)\n",
    "        ax.set_ylim(0, 1)\n",
    "        ax.yaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        clean_lang = lang.replace('(', '').replace(')', '').replace(' ', '_').lower()\n",
    "        plt.savefig(f'visualizations/example_count_{clean_lang}.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    \n",
    "    # 4. Create a summary plot comparing average model performance\n",
    "    model_avg = comparison_df.groupby('model')['overall'].mean().reset_index()\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    ax = sns.barplot(\n",
    "        x='model',\n",
    "        y='overall',\n",
    "        data=model_avg,\n",
    "        palette=palette\n",
    "    )\n",
    "    \n",
    "    # Add value labels on top of bars\n",
    "    for i, v in enumerate(model_avg['overall']):\n",
    "        ax.text(i, v + 0.02, f'{v:.2%}', ha='center', fontsize=12)\n",
    "    \n",
    "    # Customize the plot\n",
    "    ax.set_title('Average Performance Across All Languages', fontsize=16)\n",
    "    ax.set_xlabel('AI Model', fontsize=14)\n",
    "    ax.set_ylabel('Average Performance Score', fontsize=14)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.yaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('visualizations/average_performance.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 5. Create radar charts for multi-dimensional performance comparison\n",
    "    # First, prepare the data by averaging metrics across languages for each model\n",
    "    metrics = ['bleu_score', 'syntax_valid_rate', 'structure_score', 'semantic_score', 'token_match', 'overall']\n",
    "    radar_df = comparison_df.groupby('model')[metrics].mean().reset_index()\n",
    "    \n",
    "    # Normalize syntax_valid_rate to 0-1 scale\n",
    "    radar_df['syntax_valid_rate'] = radar_df['syntax_valid_rate'] / 100\n",
    "    \n",
    "    # Create the radar chart\n",
    "    labels = ['BLEU Score', 'Syntax Valid Rate', 'Structure Score', 'Semantic Score', 'Token Match', 'Overall']\n",
    "    num_vars = len(labels)\n",
    "    \n",
    "    # Compute angle for each axis\n",
    "    angles = np.linspace(0, 2 * np.pi, num_vars, endpoint=False).tolist()\n",
    "    angles += angles[:1]  # Close the loop\n",
    "    \n",
    "    # Set up the plot\n",
    "    fig, ax = plt.subplots(figsize=(12, 10), subplot_kw=dict(polar=True))\n",
    "    \n",
    "    # Plot data for each model\n",
    "    for i, model in enumerate(radar_df['model']):\n",
    "        values = radar_df[radar_df['model'] == model][metrics].values.flatten().tolist()\n",
    "        values += values[:1]  # Close the loop\n",
    "        \n",
    "        color = palette[model]\n",
    "        ax.plot(angles, values, 'o-', linewidth=2, label=model, color=color)\n",
    "        ax.fill(angles, values, alpha=0.1, color=color)\n",
    "    \n",
    "    # Set chart properties\n",
    "    ax.set_thetagrids(np.degrees(angles[:-1]), labels)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_title('AI Model Performance Across Metrics', fontsize=16, pad=20)\n",
    "    ax.legend(loc='upper right', bbox_to_anchor=(0.1, 0.1))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('visualizations/radar_chart.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 6. Create a facet grid showing all metrics by model and language\n",
    "    # Melt the dataframe to get all metrics in one column\n",
    "    melted_df = pd.melt(\n",
    "        comparison_df, \n",
    "        id_vars=['model', 'language_display'], \n",
    "        value_vars=metrics,\n",
    "        var_name='metric', \n",
    "        value_name='score'\n",
    "    )\n",
    "    \n",
    "    # Rename metrics for better display\n",
    "    metric_names = {\n",
    "        'bleu_score': 'BLEU Score',\n",
    "        'syntax_valid_rate': 'Syntax Valid Rate',\n",
    "        'structure_score': 'Structure Score',\n",
    "        'semantic_score': 'Semantic Score',\n",
    "        'token_match': 'Token Match',\n",
    "        'overall': 'Overall'\n",
    "    }\n",
    "    melted_df['metric'] = melted_df['metric'].map(metric_names)\n",
    "    \n",
    "    # Scale syntax_valid_rate to 0-1\n",
    "    melted_df.loc[melted_df['metric'] == 'Syntax Valid Rate', 'score'] = melted_df.loc[melted_df['metric'] == 'Syntax Valid Rate', 'score'] / 100\n",
    "    \n",
    "    # Create the facet grid\n",
    "    g = sns.catplot(\n",
    "        data=melted_df,\n",
    "        x='language_display',\n",
    "        y='score',\n",
    "        hue='model',\n",
    "        col='metric',\n",
    "        kind='bar',\n",
    "        height=4,\n",
    "        aspect=1.2,\n",
    "        sharey=False,\n",
    "        palette=palette,\n",
    "        col_wrap=3\n",
    "    )\n",
    "    \n",
    "    # Customize the plot\n",
    "    g.set_xticklabels(rotation=45, ha='right')\n",
    "    g.set_titles(\"{col_name}\")\n",
    "    g.set_axis_labels(\"Language\", \"Score\")\n",
    "    \n",
    "    # Format y-axis as percentage where appropriate\n",
    "    for ax in g.axes.flat:\n",
    "        ax.yaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n",
    "        ax.set_ylim(0, 1)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('visualizations/metrics_by_language.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(\"All visualizations have been generated and saved to the 'visualizations' folder!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    generate_visualizations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c219f9ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pylinguist",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
